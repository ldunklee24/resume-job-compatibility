{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBRBz7G1IUSG"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "software_jobs = []\n",
        "data_jobs = []"
      ],
      "metadata": {
        "id": "rCYprAjfLpLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_job(job_category, job_id, job_title, company, location,\n",
        "               description, required_skills, preferred_skills, years_experience):\n",
        "    job = {\n",
        "        \"job_category\": job_category,\n",
        "        \"job_id\": job_id,\n",
        "        \"job_title\": job_title,\n",
        "        \"company\": company,\n",
        "        \"location\": location,\n",
        "        \"job_description_text\": description,\n",
        "        \"required_skills\": required_skills,\n",
        "        \"preferred_skills\": preferred_skills,\n",
        "        \"years_experience\": years_experience\n",
        "    }\n",
        "\n",
        "    if job_category == \"software\":\n",
        "        software_jobs.append(job)\n",
        "    elif job_category == \"data\":\n",
        "        data_jobs.append(job)\n",
        "    else:\n",
        "        raise ValueError(\"job_category must be 'software' or 'data'\")"
      ],
      "metadata": {
        "id": "TrYwJ18eL-LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Create JSON files for software jobs\n",
        "'''\n",
        "\n",
        "create_job(\"software\", \"job_001\", \"Software Engineer I\", \"SEACORP\", \"Newport, RI\", \"SEACORP is seeking an entry-level Software Engineer to work within \"\n",
        "        \"a multidisciplinary team to define, design, develop, test, and \"\n",
        "        \"integrate software capabilities into complex military systems. \"\n",
        "        \"The role involves contributing to key features, enhancing existing \"\n",
        "        \"applications, and participating in the full software development lifecycle. \"\n",
        "        \"Responsibilities include designing, coding, testing, integrating, \"\n",
        "        \"and documenting software solutions; working within agile workflows; \"\n",
        "        \"and contributing to both front-end and back-end development.\", ['C++', 'Java', 'Python', 'Linux', 'Agile'], ['Atlassian Tools'], 0)\n",
        "\n",
        "create_job(\"software\", 'job_002', 'Software Engineer II', 'Raytheon', 'Tewksbury, MA', \"Raytheon is hiring a Software Development Engineer II to work within the \"\n",
        "    \"Air & Missile Defense Software Department on the Patriot Software Development Team. \"\n",
        "    \"The role involves assisting with requirements, design, development, and testing \"\n",
        "    \"of real-time embedded software, application software, and tools, including \"\n",
        "    \"creating new work products and enhancing existing applications. \"\n",
        "    \"Responsibilities include designing, coding, testing, integrating, and documenting \"\n",
        "    \"software solutions, participating in internal software reviews, collaborating with \"\n",
        "    \"project managers and engineers, and following established development practices to \"\n",
        "    \"maintain software configuration management.\",\n",
        "     ['C++', 'C', 'Java', 'Unix/Linux', 'Software Development'],\n",
        "      ['Data Structures', 'Algorithms', 'Agile/SCRUM', 'DevOps', 'Test Automation'],\n",
        "           0)\n",
        "\n",
        "create_job('software',\n",
        "           'job_003',\n",
        "           'Python Developer',\n",
        "           'Infosys',\n",
        "           'Hartford, CT',\n",
        "           \"Infosys is seeking a GCP & Python Developer to work across the Software Development Life Cycle, \"\n",
        "    \"including requirements elicitation, application architecture definition, and design. \"\n",
        "    \"The role involves creating high-level design artifacts, delivering high-quality code for modules, \"\n",
        "    \"leading validation for all types of testing, and supporting implementation, transition, and warranty activities. \"\n",
        "    \"This position requires collaboration with stakeholders and teamwork in a learning culture that values excellence and diversity.\",\n",
        "           ['python', 'agile', 'ETL Tools', 'GCP Services'],\n",
        "           ['modeling', 'GCP Certifications'],\n",
        "           2)\n",
        "\n",
        "create_job('software',\n",
        "           'job_004',\n",
        "           'Associate Engineer',\n",
        "           'Man Group',\n",
        "           'Boston, MA',\n",
        "           \"As a member of the Business and Investment Production Support (BIPS) team at Man Group, \"\n",
        "    \"the associate engineer will maintain and monitor automated investment processes, including database jobs, modeling tasks, reporting, and analytics. \"\n",
        "    \"The role involves deploying new models and simulators, overseeing the production environment, debugging real-time issues, coordinating schedule changes with developers, \"\n",
        "    \"managing production incidents, executing releases, and recommending workflow enhancements. \"\n",
        "    \"The position requires collaboration with developers, researchers, and portfolio managers to implement new strategies and improve production processes.\",\n",
        "           ['Unix/Linux', 'SQL', 'Python'],\n",
        "           ['finance', 'Control-M', 'Source control tools', 'relational databases'],\n",
        "           0\n",
        "           )\n",
        "\n",
        "create_job('software',\n",
        "           'job_005',\n",
        "           'Associate Software Engineer',\n",
        "           'Veeva Systems',\n",
        "           'Boston, MA',\n",
        "           \"Veeva Systems is hiring recent university graduates for its Engineering Development Program to grow the next generation of Software Engineers. \"\n",
        "    \"The program provides a challenging environment to learn quickly, deliver value early, and develop technical and professional skills. \"\n",
        "    \"Participants will work on system software, application logic, front-end, and mobile development using languages such as Java, Python, TypeScript, JavaScript, Swift, and Kotlin. \"\n",
        "    \"The role involves coding, collaborating with engineering teams, and applying fundamental computer science knowledge to contribute to software projects in a fast-paced, learning-focused environment.\",\n",
        "           ['Operating Systems', 'Compilers', 'Java', 'Python', 'JavaScript'],\n",
        "           ['TypeScript', 'React', 'React Native', 'Swift', 'Kotlin'],\n",
        "           0)\n",
        "\n",
        "create_job('software',\n",
        "           'job_006',\n",
        "           'Entry Level Software Engineer',\n",
        "           'BAE Systems Inc.',\n",
        "           'Hudson, NH',\n",
        "           \"As an Entry-Level Software Engineer at BAE Systems, you will design, develop, and test software for advanced defense and space systems. \"\n",
        "    \"The role involves contributing to the full software lifecycle, including coding, debugging, integration, and system testing, \"\n",
        "    \"while collaborating with system, hardware, and test engineers. \"\n",
        "    \"You will support field demonstrations, software installations, and system-level testing, gaining exposure to advanced technologies and tools as you build your technical foundation.\",\n",
        "           ['C', 'C++', 'Java', 'Python', 'Object Oriented Design'],\n",
        "           ['Security Clearance', 'version control', 'Agile', 'DevOps'],\n",
        "           0)\n",
        "\n",
        "create_job('software',\n",
        "           'job_007',\n",
        "           'Full Stack Engineer',\n",
        "           'C2R Ventures',\n",
        "           'Boston, MA',\n",
        "           \"The Full Stack Engineer will work in the Research and Portfolio Systems Group to design, develop, deploy, and support mission-critical applications for research, portfolio construction, and portfolio management. \"\n",
        "    \"Responsibilities include developing and maintaining Python-based backend services, building RESTful APIs and data pipelines, enhancing applications using the .NET and Python stacks, creating new system components with TDD and SOLID principles, \"\n",
        "    \"participating in code reviews and analysis, and ensuring adherence to architecture and coding standards. \"\n",
        "    \"The role involves close collaboration with Developers, Product Owners, and Quant Research teams to deliver calculation-intensive software solutions for quantitative research and portfolio analytics.\",\n",
        "           ['Python', 'Object Oriented Design', '.NET', 'FastAPI', 'Flask', 'Django', 'SQL', 'React', 'TypeScript', 'HTML', 'CSS', \"AZURE\"],\n",
        "           ['Docker', 'Kubernetes', 'CI/CD', 'finance', 'Vector Databases', 'large language models', 'machine learning', 'NLP'],\n",
        "           0)\n",
        "\n",
        "create_job('software',\n",
        "           'job_008',\n",
        "           'Entry Level Software Developer',\n",
        "           'IBM',\n",
        "           'Lowell, MA',\n",
        "           \"As an Entry-Level Software Developer at IBM, you will join a collaborative Agile team to design, build, and deploy modern web applications. \"\n",
        "    \"The role involves contributing to all stages of the development cycle, working with APIs, databases, and cloud services to build scalable solutions, \"\n",
        "    \"applying Agile and DevOps practices, collaborating with UX designers and senior developers, and learning from mentorship and code reviews to grow technical skills.\",\n",
        "           ['Java', 'C', 'C++', 'PL/I', 'Assembler', 'GitHub', 'Python', 'JavaScript', 'TypeScript', 'Ruby', 'Rust', 'Swift', 'Kotlin'],\n",
        "           ['CI/CD', 'IBM Z Architecture', 'Agile', 'IBM z/OS', 'Db2', 'MongoDB', 'IMS', 'SQL', 'NoSQL', 'MySQL', 'JavaScript', 'HTML5', 'CSS3', 'jQuery', 'Node.js', 'React', 'DOM', 'JSON', 'CSS', 'HTTP', 'SSL', 'MQ', 'TCP/IP', 'VCP', 'Kubernetes', 'OpenShift', 'Istio', 'Akamai', 'REST APIs', 'VS Code', 'Linux', 'Springboot', 'Liberty', 'Quarkus', 'Grails', 'Artificial Intelligence', 'Machine Learning'],\n",
        "           0)\n",
        "\n",
        "create_job('software',\n",
        "           'job_009',\n",
        "           'Python Developer, Officer',\n",
        "           'State Street',\n",
        "           'Quincy, MA',\n",
        "           \"As a Python Developer at State Street, you will design and deliver secure, scalable backend services and data pipelines for the AML Transaction Monitoring platform. \"\n",
        "    \"The role involves developing Python APIs using frameworks like FastAPI and Django, building ETL processes and Delta tables with Databricks, \"\n",
        "    \"utilizing cloud platforms for data processing and analytics, and contributing across the full development cycle with a focus on scalability and performance.\",\n",
        "           ['Python', 'AWS', 'Django', 'Fast API', ],\n",
        "           ['PySpark', 'Databricks', 'ETL', 'Agile', 'FCC', 'TRM Labs', 'Coinbase', 'GraphQL'],\n",
        "           3)\n",
        "\n",
        "create_job('software',\n",
        "           'job_010',\n",
        "           'Junior Software Engineer',\n",
        "           'General Dynamics Mission Systems',\n",
        "           'Dedham, MA',\n",
        "           \"As a Software Engineer at General Dynamics Mission Systems, you will assist in the research, design, development, and testing of software and tools, \"\n",
        "    \"including creating new work products and enhancing existing applications, systems, or embedded products. \"\n",
        "    \"The role involves coding, testing, and documenting software solutions while working within a team to advance technology solutions in cybersecurity, encryption, and other advanced domains.\",\n",
        "           ['C', 'C++'],\n",
        "           ['Agile'],\n",
        "           0)"
      ],
      "metadata": {
        "id": "4_gJzXpOM24w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Create JSON files for data jobs\n",
        "'''\n",
        "\n",
        "create_job('data',\n",
        "           'job_001',\n",
        "           'Data Engineer',\n",
        "           'HarbourVest Partners',\n",
        "           'Boston, MA',\n",
        "           \"As a Data Engineer at HarbourVest, you will transform the firmâ€™s data infrastructure using Snowflake and the Azure data stack. \"\n",
        "    \"The role involves implementing and supporting Snowflake-based data pipelines, analyzing business and technical requirements to contribute to data models, \"\n",
        "    \"designing and building data validations, transformations, reports, and integration processes, creating CI/CD pipelines, and organizing work using Agile techniques. \"\n",
        "    \"You will collaborate with product owners, data owners, project managers, business users, peer data engineers, and infrastructure engineers to deliver end-to-end data solutions.\",\n",
        "           ['Snowflake', 'CI/CD', 'SQL', 'Python', 'Dagster', 'Agile'],\n",
        "           ['Azure'],\n",
        "           3)\n",
        "\n",
        "create_job('data',\n",
        "           'job_002',\n",
        "           'Data Engineer I',\n",
        "           'Travelers',\n",
        "           'Hartford, CT',\n",
        "           \"As a Data Engineer at Travelers, you will design, build, and operationalize complex data solutions to support analytics, AI, ML, and business intelligence. \"\n",
        "    \"The role involves developing data pipelines, performing data transformations, ensuring data quality and governance, collaborating across teams, \"\n",
        "    \"testing data movement and transformation code, and analyzing data sources to inform analytical processes.\",\n",
        "           ['SQL', 'Python', \"AWS\", 'S3', 'Glue', 'Athena'],\n",
        "           ['CI/CD', 'Artificial Intelligence', 'Machine Learning'],\n",
        "           2)\n",
        "\n",
        "create_job('data',\n",
        "           'job_003',\n",
        "           'Data Product Engineer',\n",
        "           'Verisk',\n",
        "           'Middletown, CT',\n",
        "           \"As a Data Analyst on the MarketStance Data Team, you will transform disparate data sources into a model of the U.S. economy and commercial insurance market. \"\n",
        "    \"Responsibilities include operating and maintaining data modeling routines in Microsoft SQL Server, creating data models and metadata, conducting quality assurance, \"\n",
        "    \"leveraging government and private datasets to inform exposure estimates, conducting secondary research on commercial insurance, and presenting findings to internal and external clients.\",\n",
        "           ['MS SQL', 'MS Excel', 'MS Powerpoint', 'Analytical Writing'],\n",
        "           ['Actuary', 'R', 'SAS', 'Python', 'GIS'],\n",
        "           0)\n",
        "\n",
        "create_job('data',\n",
        "           'job_004',\n",
        "           'Data Analyst',\n",
        "           'Parsons',\n",
        "           'Meyer Camp, HI',\n",
        "           \"As a Data Analyst at Parsons supporting US INDOPACOM, you will collaborate with stakeholders to collect, analyze, and interpret structured and unstructured data \"\n",
        "    \"to support strategic initiatives. You will produce actionable use cases for command staff, educate users on data interpretation, automate data processing and analysis tasks, \"\n",
        "    \"and communicate complex technical information clearly to technical and non-technical audiences.\",\n",
        "           ['Python', 'R', 'SQL', 'TensorFlow', 'scikit-learn', 'PyTorch', 'matplotlib', 'Pandas', 'Spark'],\n",
        "           ['data visualization', 'security clearance'],\n",
        "           2)\n",
        "\n",
        "create_job('data',\n",
        "           'job_005',\n",
        "           'Data Analyst',\n",
        "           'ADP',\n",
        "           'Denver, CO',\n",
        "           \"As a Sr. Data Analytics Consultant at ADP, you will work closely with business stakeholders to understand objectives and deliver data-driven insights. \"\n",
        "    \"Responsibilities include managing data and analytics projects, extracting and analyzing data from multiple systems, developing and maintaining reports and self-service tools, \"\n",
        "    \"translating technical findings into clear recommendations for non-technical audiences, and supporting data governance and ad-hoc requests.\",\n",
        "           ['SQL', 'Excel'],\n",
        "           ['Microsoft Word', 'Microsoft Powerpoint', 'Tableau', ' PowerBI', 'Qlik', 'Looker'],\n",
        "           2\n",
        "           )\n",
        "\n",
        "create_job('data',\n",
        "           'job_006',\n",
        "           'Data & AI Consultant',\n",
        "           'Thorogood',\n",
        "           'Boston, MA',\n",
        "           \"As an entry-level consultant at Thorogood, you will work with clients to develop data-focused technical solutions, \"\n",
        "    \"build core technology skills, and participate in client interactions. Responsibilities include contributing to project teams, \"\n",
        "    \"analyzing and transforming data, developing analytical and technical expertise, supporting business development activities, \"\n",
        "    \"and helping deliver educational and marketing events. You will also assist in internal consultancy growth through recruiting, training, \"\n",
        "    \"and knowledge sharing. This role involves hybrid work from the Boston office with occasional travel to client sites.\",\n",
        "           ['Cloud BI', \"AWS\", 'Azure', 'Google Cloud', 'SQL', 'Python', 'R', 'Scala', 'Spark'],\n",
        "           ['machine learning', 'artificial intelligence', 'probability', 'data visualization'],\n",
        "           0)\n",
        "\n",
        "create_job('data',\n",
        "           'job_007',\n",
        "           'Machine Learning Engineer',\n",
        "           'Next Insurance',\n",
        "           'Boston, MA',\n",
        "           \"As a Backend Engineer at NEXT, you will design, implement, and optimize backend services supporting AI workflows, \"\n",
        "    \"integrate ML and LLM models into production systems, collaborate with product and cross-functional teams to refine requirements, \"\n",
        "    \"contribute to system design and architecture reviews, diagnose complex issues across data pipelines and backend components, \"\n",
        "    \"and drive technical initiatives to support innovation and continuous improvement. The role supports a hybrid work model with \"\n",
        "    \"a minimum of two days per week on-site.\",\n",
        "           ['Python', 'GO', 'Java', 'Machine Learning', 'Large Language Models'],\n",
        "           ['Cloud Infrastructure'],\n",
        "           2)\n",
        "\n",
        "create_job('data',\n",
        "           'job_008',\n",
        "           'AI Engineer',\n",
        "           'GEI Consultants Inc.',\n",
        "           'Wakefield, MA',\n",
        "           \"As an AI Engineer at GEI, you will build, deploy, and integrate AI solutions using pretrained models and Copilot technologies, \"\n",
        "    \"design prompt flows and orchestrations, integrate AI capabilities into business workflows and enterprise data sources, maintain \"\n",
        "    \"and optimize AI-enabled Power BI dashboards, instrument solutions for telemetry and performance monitoring, and provide technical \"\n",
        "    \"support and troubleshooting. The role focuses on delivering scalable, secure, and production-ready Generative AI applications \"\n",
        "    \"and collaborating with solution architects and platform teams.\",\n",
        "           ['Large Language Models', 'Python', 'PySpark', 'R', 'SQL', 'Spark', 'Databricks', 'Azure AI Platform', 'Azure Data Factory', 'Azure Synapse', 'Azure Cognitive Services'],\n",
        "           ['Azure', 'TensorFlow', 'PyTorch', 'Azure AI Engineer Associate', 'Azure Solutions Architect Expert', 'Databricks ML Professional', 'Databricks Data Engineer Professional'],\n",
        "           4)\n",
        "\n",
        "create_job('data',\n",
        "           'job_009',\n",
        "           'Data Engineer',\n",
        "           'Keystone',\n",
        "           'Boston, MA',\n",
        "           \"As a Data Engineer at Keystone within the ETSA group, you will design, build, and optimize data systems supporting high-impact \"\n",
        "    \"analytical and forensic engagements. You will partner with consultants to architect secure, high-performance data infrastructure \"\n",
        "    \"across cloud environments, develop reproducible data ingestion pipelines and analytical workflows, build custom software and APIs \"\n",
        "    \"to automate data discovery and integrate LLMs, leverage ETL/ELT, SQL, and big data technologies, implement tools for scalability \"\n",
        "    \"and auditability, support AI/ML-driven analysis including model fine-tuning and deployment, advise on data governance and compliance, \"\n",
        "    \"and collaborate with cross-functional teams to deliver innovative client outcomes.\",\n",
        "           ['SQL', 'JSON', 'CSV', 'AWS', 'GCP', 'Azure', 'Lambda', 'Bedrock', 'Vertex AI', 'Python', 'R', 'PyTorch', 'TensorFlow', 'scikit-learn','Hugging Face', 'OpenAI API'],\n",
        "           ['Airflow', 'dbt', 'Prefect', 'Luigi', 'Snowflake', 'Spark', 'BigQuery', 'Git', 'CI/CD'],\n",
        "           0)\n",
        "\n",
        "create_job('data',\n",
        "           'job_010',\n",
        "           'Data Engineer - Cloud',\n",
        "           'CapTech',\n",
        "           'Denver, CO',\n",
        "           \"As a Cloud Data Engineer at CapTech, you will design and implement data pipelines and products using cloud platforms \"\n",
        "    \"like AWS, Azure, or GCP. You will collaborate with clients, developers, and analysts to build scalable and efficient data solutions, \"\n",
        "    \"apply engineering best practices to solve complex problems, implement data architecture designs, develop production-ready pipelines, \"\n",
        "    \"and leverage SQL, Python, and modern cloud technologies. You will also advise clients on architectural trade-offs and help maximize \"\n",
        "    \"the business value of their data.\",\n",
        "           ['SQL', 'Python', 'Java', 'R', 'C#', 'C++', 'C', 'SQL Server', 'PostgreSQL', 'Snowflake', 'Redshift', 'Aurora', 'Presto', 'BigQuery', 'Oracle', 'git', 'docker', 'subversion', 'kubernetes', 'Jenkins'],\n",
        "           ['Spark', 'Databricks', 'Kafka', 'Kineses', 'Hadoop', 'Lambda', 'EMR', 'AWS Cloud Practitioner', 'Microsoft Azure Data Fundamentals', 'Google Associate Cloud Engineer'],\n",
        "           0\n",
        "           )"
      ],
      "metadata": {
        "id": "aNCtzlN8md3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6xb2VhW2bw1",
        "outputId": "cd86cb16-4dd6-4718-a6c2-89b25e7e4195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "software_jobs_file = '/content/drive/MyDrive/Resume_Project/software_jobs.json'\n",
        "data_jobs_file = '/content/drive/MyDrive/Resume_Project/data_jobs.json'\n",
        "\n",
        "for path in [software_jobs_file, data_jobs_file]:\n",
        "  if not os.path.exists(path):\n",
        "    with open(path, 'w') as f:\n",
        "      json.dump([], f)"
      ],
      "metadata": {
        "id": "aYuVJEWh2v2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(software_jobs_file, 'w') as f:\n",
        "  json.dump(software_jobs, f, indent=4)\n",
        "\n",
        "with open(data_jobs_file, 'w') as f:\n",
        "  json.dump(data_jobs, f, indent=4)"
      ],
      "metadata": {
        "id": "bXyT_SSn5in4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}